{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting V4 voxels from Alexnet conv3 features - take #2\n",
    "Here we're trying again to find a mapping from the alexnet conv3 feature space to the V4 voxel space. But this time the features come from 'retinawarp'ed' input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic imports\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import RidgeCV, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and organize brain data\n",
    "\n",
    "#read in the mat files\n",
    "with h5py.File('data/EstimatedResponses.mat','r') as fmri_dataset:\n",
    "    train_S1 = fmri_dataset['dataTrnS1'][:]\n",
    "    test_S1 = fmri_dataset['dataValS1'][:]\n",
    "    roi_S1 = fmri_dataset['roiS1'][:]\n",
    "    \n",
    "    train_S2 = fmri_dataset['dataTrnS2'][:]\n",
    "    test_S2 = fmri_dataset['dataValS2'][:]\n",
    "    roi_S2 = fmri_dataset['roiS2'][:]\n",
    "    \n",
    "    unique_ROIs = np.unique((fmri_dataset['roiS1'])) \n",
    "    \n",
    "#organize subject 1\n",
    "S1_train_data_by_ROI = {c: train_S1[:,roi_S1[0,:] == c] \n",
    "                       for c in unique_ROIs}\n",
    "S1_test_data_by_ROI = {c: test_S1[:,roi_S1[0,:] == c] \n",
    "                       for c in unique_ROIs}\n",
    "#organize subject 2\n",
    "S2_train_data_by_ROI = {c: train_S2[:,roi_S2[0,:] == c] \n",
    "                       for c in unique_ROIs}\n",
    "S2_test_data_by_ROI = {c: test_S2[:,roi_S2[0,:] == c] \n",
    "                       for c in unique_ROIs}\n",
    "\n",
    "#Select only V4 voxels & get rid of any voxels that have NaNs for any training images\n",
    "#Subject 1\n",
    "S1_V4 = S1_train_data_by_ROI[6.0].T\n",
    "x=S1_V4[~np.isnan(S1_V4).any(axis=1)]\n",
    "S1_V4_train = x.T\n",
    "S1_V4_val = S1_test_data_by_ROI[6.0].T\n",
    "x=S1_V4_val[~np.isnan(S1_V4).any(axis=1)]\n",
    "S1_V4_test = x.T\n",
    "#Subject 2\n",
    "S2_V4 = S2_train_data_by_ROI[6.0].T\n",
    "x=S2_V4[~np.isnan(S2_V4).any(axis=1)]\n",
    "S2_V4_train = x.T\n",
    "S2_V4_val = S2_test_data_by_ROI[6.0].T\n",
    "x=S2_V4_val[~np.isnan(S2_V4).any(axis=1)]\n",
    "S2_V4_test = x.T\n",
    "sum(sum(np.isnan(S2_V4_test))) #make sure we don't have any NaNs left in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the alexnet features\n",
    "h5f = h5py.File('alexnet/alexnet_conv3_features_retinawarp.h5','r')\n",
    "train_features = h5f['train'][:] #features for the training images\n",
    "val_features = h5f['val'][:] #features for the validation images\n",
    "h5f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
